# ==============================================================
# SpacesAI Environment Configuration (Annotated)
# Each setting includes a short explanation of its purpose.
# Copy this to .env and adjust values for your deployment.
# ==============================================================

# ------------------------------
# Server
# ------------------------------
# HOST: Bind address for the web server (0.0.0.0 = all interfaces)
HOST=0.0.0.0
# PORT: HTTP port for the app
PORT=8000
# WORKERS: Number of server workers
WORKERS=1

# ------------------------------
# Storage
# ------------------------------
# DATA_DIR: Root folder for local storage
DATA_DIR=storage
# UPLOAD_DIR: Temporary upload directory
UPLOAD_DIR=storage/uploads

# ------------------------------
# Database (choose either DATABASE_URL or the discrete params)
# ------------------------------
# DATABASE_URL: Full Postgres connection string (overrides discrete params)
# DATABASE_URL=postgresql://USER:PASSWORD@HOST:5432/DBNAME?sslmode=require
# DB_HOST/DB_PORT/DB_NAME/DB_USER/DB_PASSWORD: Discrete Postgres connection parts
DB_HOST=10.10.1.82
DB_PORT=5432
DB_NAME=postgres
DB_USER=postgres
DB_PASSWORD=RAbbithole1234##
# DB_SSLMODE: SSL mode for Postgres (require/refer to pg docs)
DB_SSLMODE=require
# DB_POOL_MIN_SIZE/DB_POOL_MAX_SIZE: Connection pool size bounds
DB_POOL_MIN_SIZE=1
DB_POOL_MAX_SIZE=10

# ------------------------------
# Embeddings
# ------------------------------
# EMBEDDING_MODEL: Embedding model identifier
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# EMBEDDING_DIM: Embedding dimension size (must match model)
EMBEDDING_DIM=384
# EMBEDDING_BATCH: Batch size for embedding jobs
EMBEDDING_BATCH=64
# DB_STORE_EMBEDDINGS: Persist embeddings in Postgres (enables pgvector)
DB_STORE_EMBEDDINGS=false

# ------------------------------
# pgvector index (used only if SEARCH_BACKEND=pgvector)
# ------------------------------
# PGVECTOR_METRIC: cosine | l2 | ip
PGVECTOR_METRIC=cosine
# PGVECTOR_LISTS: IVF list count (tune for corpus size)
PGVECTOR_LISTS=1000
# PGVECTOR_PROBES: Search probes (higher = better recall, slower)
PGVECTOR_PROBES=25

# ------------------------------
# Full-text search
# ------------------------------
# FTS_CONFIG: PostgreSQL text search configuration (language)
FTS_CONFIG=english

# ------------------------------
# Security & Auth
# ------------------------------
# BASIC_AUTH_USER/PASSWORD: fallback auth (used for testing)
BASIC_AUTH_USER=admin
BASIC_AUTH_PASSWORD=letmein
# APP_NAME: UI display name
APP_NAME=SpacesAI
# SECRET_KEY: Session signing key (change in production)
SECRET_KEY=change-me-please
# SESSION_COOKIE_NAME: Cookie name for session
SESSION_COOKIE_NAME=spacesai_session
# SESSION_MAX_AGE_SECONDS: Session lifetime (seconds)
SESSION_MAX_AGE_SECONDS=1209600
# COOKIE_SECURE: true if served over HTTPS
COOKIE_SECURE=false
# COOKIE_SAMESITE: Lax/Strict/None
COOKIE_SAMESITE=Lax
# ALLOW_REGISTRATION: allow self-signup
ALLOW_REGISTRATION=true

# ------------------------------
# Optional LLM for RAG synthesis
# ------------------------------
# LLM_PROVIDER: none | openai | oci | bedrock | ollama
LLM_PROVIDER=oci
# OPENAI_API_KEY / OPENAI_MODEL: OpenAI settings
OPENAI_API_KEY=
OPENAI_MODEL=

# ------------------------------
# OCI Generative AI (when LLM_PROVIDER=oci)
# ------------------------------
OCI_REGION=mx-queretaro-1
OCI_COMPARTMENT_OCID=ocid1.compartment.oc1..aaaaaaaadfdmligjm7aefhatq6n5s2stavjgfq56n7vbnhjpxry7tiqjgmfa
OCI_GENAI_ENDPOINT=https://inference.generativeai.us-chicago-1.oci.oraclecloud.com
OCI_GENAI_MODEL_ID=ocid1.generativeaimodel.oc1.us-chicago-1.amaaaaaask7dceyayjawvuonfkw2ua4bob4rlnnlhs522pafbglivtwlfzta
# Option 1: Use config file
OCI_CONFIG_FILE=/home/opc/.oci/config
OCI_CONFIG_PROFILE=DEFAULT
# Option 2: API key envs
OCI_TENANCY_OCID=
OCI_USER_OCID=
OCI_FINGERPRINT=
OCI_PRIVATE_KEY_PATH=
OCI_PRIVATE_KEY_PASSPHRASE=

# ------------------------------
# CORS
# ------------------------------
# ALLOW_CORS: enable CORS middleware
ALLOW_CORS=true
# CORS_ORIGINS: Comma-separated list of allowed origins
CORS_ORIGINS=*

# ------------------------------
# Upload & PDF parsing
# ------------------------------
# MAX_UPLOAD_SIZE_MB: per-file size limit
MAX_UPLOAD_SIZE_MB=200
# MAX_UPLOAD_FILES: per-batch count limit
MAX_UPLOAD_FILES=100
# USE_PYMUPDF: Use PyMuPDF for PDF parsing
USE_PYMUPDF=true
# DELETE_UPLOADED_FILES: delete uploaded files after ingestion
DELETE_UPLOADED_FILES=false

# ------------------------------
# Storage backend
# ------------------------------
# STORAGE_BACKEND: local | oci | both
STORAGE_BACKEND=oci
# OCI_OS_BUCKET_NAME: Object storage bucket
OCI_OS_BUCKET_NAME=search-app-uploads
# OCI_OS_UPLOAD: enable OCI Object Storage uploads
OCI_OS_UPLOAD=true

# ------------------------------
# Retrieval backend
# ------------------------------
# SEARCH_BACKEND: opensearch | pgvector
SEARCH_BACKEND=opensearch

# ------------------------------
# OpenSearch
# ------------------------------
OPENSEARCH_HOST=https://amaaaaaawiclygaashyteiqunkonejhfurxooxj2vv6ubcrflyruk5oa34tq.opensearch.mx-queretaro-1.oci.oraclecloud.com:9200
OPENSEARCH_INDEX=spacesai_chunks
OPENSEARCH_USER=osmaster
OPENSEARCH_PASSWORD=RAbbithole1234##
OPENSEARCH_TIMEOUT=120
OPENSEARCH_MAX_RETRIES=8
OPENSEARCH_VERIFY_CERTS=true
OPENSEARCH_DUAL_WRITE=true
# Index layout
OPENSEARCH_SHARDS=3
OPENSEARCH_REPLICAS=1
# OPENSEARCH_KNN_NUM_CANDIDATES: optional KNN candidate tuning
# OPENSEARCH_KNN_NUM_CANDIDATES=500

# ------------------------------
# Image index configuration
# ------------------------------
IMAGE_INDEX_NAME=spacesai_images
IMAGE_INDEX_SHARDS=3
IMAGE_INDEX_REPLICAS=1

# ------------------------------
# Valkey (Redis-compatible) cache
# ------------------------------
VALKEY_HOST=aaawiclygaa5mj533ohobwqjuel7arrc5dke6b5vkbebytopurv5uva-p.redis.mx-queretaro-1.oci.oraclecloud.com
VALKEY_PORT=6379
VALKEY_PASSWORD=
VALKEY_DB=0
VALKEY_TLS=true
# CACHE_TTL_SECONDS: default cache TTL
CACHE_TTL_SECONDS=300

# ------------------------------
# AWS Bedrock (optional)
# ------------------------------
AWS_REGION=us-east-1
AWS_BEDROCK_MODEL_ID=anthropic.claude-3-sonnet-20240229-v1:0

# ------------------------------
# Ollama (optional)
# ------------------------------
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2:latest

# ------------------------------
# Chunking (ingestion)
# ------------------------------
# CHUNK_SIZE/CHUNK_OVERLAP: default chunking
CHUNK_SIZE=2500
CHUNK_OVERLAP=250
# CHUNK_AUTO_TUNE: auto-tune chunk size to document structure
CHUNK_AUTO_TUNE=true
# CHUNK_MIN_SIZE/CHUNK_MAX_SIZE: bounds for auto-tuning
CHUNK_MIN_SIZE=800
CHUNK_MAX_SIZE=3500
# CHUNK_OVERLAP_RATIO: proportional overlap for auto-tuning
CHUNK_OVERLAP_RATIO=0.1

# ------------------------------
# Vision embeddings
# ------------------------------
IMAGE_EMBED_MODEL=openclip/ViT-B-32
IMAGE_EMBED_DIM=512
IMAGE_EMBED_DEVICE=cpu
ENABLE_IMAGE_STORAGE=true
ENABLE_TABLE_STORAGE=true

# ------------------------------
# Deep Research feature flags
# ------------------------------
# DR_RERANK_ENABLE: enable reranking toggle
DR_RERANK_ENABLE=true
# DR_TOPIC_LOCK_DEFAULT: strict topic lock default in UI
DR_TOPIC_LOCK_DEFAULT=false
# DEEP_RESEARCH_TIMEOUT_SECONDS: total DR time budget
DEEP_RESEARCH_TIMEOUT_SECONDS=120
# DEEP_RESEARCH_LOCAL_TOP_K: local chunks per subquestion
DEEP_RESEARCH_LOCAL_TOP_K=15
# DEEP_RESEARCH_WEB_TOP_K: web hits requested when web search triggers
DEEP_RESEARCH_WEB_TOP_K=15
# DEEP_RESEARCH_URL_MAX_DEPTH: crawl depth for user URLs
DEEP_RESEARCH_URL_MAX_DEPTH=2
# DEEP_RESEARCH_URL_MAX_PAGES: total pages fetched per request
DEEP_RESEARCH_URL_MAX_PAGES=12
# DEEP_RESEARCH_RETRY_LOOPS: web decision retries on low confidence
DEEP_RESEARCH_RETRY_LOOPS=1
# DEEP_RESEARCH_CONFIDENCE_THRESHOLD: minimum confidence to stop retrying
# Lower = more retries (better coverage, slower), higher = fewer retries (faster)
DEEP_RESEARCH_CONFIDENCE_THRESHOLD=0.45
# DEEP_RESEARCH_MISSING_CONCEPT_LOOPS: missing-concept retrieval passes (0 disables)
DEEP_RESEARCH_MISSING_CONCEPT_LOOPS=1
# DEEP_RESEARCH_MISSING_CONCEPT_TOP_K: max missing-concept subqueries per loop
DEEP_RESEARCH_MISSING_CONCEPT_TOP_K=6
# DEEP_RESEARCH_RECENCY_BOOST: weight added to newer sources in ranking
DEEP_RESEARCH_RECENCY_BOOST=0.15
# DEEP_RESEARCH_RECENCY_HALF_LIFE_DAYS: half-life for recency decay
DEEP_RESEARCH_RECENCY_HALF_LIFE_DAYS=30
# DEEP_RESEARCH_FOLLOWUP_ENABLE: enable follow-up prompts
DEEP_RESEARCH_FOLLOWUP_ENABLE=true
# DEEP_RESEARCH_FOLLOWUP_THRESHOLD: confidence below this triggers follow-ups
DEEP_RESEARCH_FOLLOWUP_THRESHOLD=0.4
# DEEP_RESEARCH_FOLLOWUP_MAX_QUESTIONS: cap follow-up questions returned
DEEP_RESEARCH_FOLLOWUP_MAX_QUESTIONS=2
# DEEP_RESEARCH_FOLLOWUP_AUTOSEND: auto-send follow-up chips instead of inserting text
DEEP_RESEARCH_FOLLOWUP_AUTOSEND=true
# DEEP_RESEARCH_FOLLOWUP_RELEVANCE_MIN: minimum Jaccard similarity to current question or conversation
DEEP_RESEARCH_FOLLOWUP_RELEVANCE_MIN=0.08